{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "# embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "# embeddings = embed([\n",
    "# \"The quick brown fox jumps over the lazy dog.\",\n",
    "# \"I am a sentence for which I would like to get its embedding\"])\n",
    "# session=tf.Session()\n",
    "# session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "# print (tf.Session().run(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from cytoolz import concatv\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk,pprint\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Helper libraries\n",
    "# from w266_common import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# Your code\n",
    "# import rnnlm; reload(rnnlm)\n",
    "# import rnnlm_test; reload(rnnlm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['U', '.', 'S', 'TREASURY', \"'\", 'S', 'MULFORD', 'REAFFIRMS', 'G', '-', '6', 'AGREEMENT', 'Treasury', 'Assistant', 'Secretary', 'David', 'Mulford', 'reaffirmed', 'U', '.', 'S', '.', 'backing', 'for', 'the', 'Paris', 'Agreement', 'among', 'six', 'industrial', 'nations', 'to', 'cooperate', 'closely', 'to', 'foster', 'exchange', 'rate', 'stability', 'around', 'current', 'levels', '.'], ['In', 'testimony', 'prepared', 'for', 'delivery', 'before', 'a', 'Senate', 'banking', 'subcommittee', ',', 'Mulford', 'said', 'there', 'was', 'broad', 'recognition', 'in', 'Paris', 'that', '\"', 'further', 'substantial', 'exchange', 'rate', 'shifts', 'could', 'damage', 'growth', 'and', 'adjustment', 'prospects', '.\"'], ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.reuters.sents('training/9864')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentences = np.array(list(reuters.sents('training/9864')), dtype=object)\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'Baghdad Gallery Owner Hopes Culture Can Dispel Hate'\", \"'Sweet and Sour Sit Down to Dessert'\"]\n"
     ]
    }
   ],
   "source": [
    "# need to remove quote?\n",
    "file = open('data/nyt_test.txt','rt')\n",
    "read_array = file.readlines()\n",
    "title=[]\n",
    "body=[]\n",
    "for line in read_array:\n",
    "    data = line.split(' , ') #file id, headline, leading_paragraph and full_text\n",
    "    title.append(data[1])\n",
    "    body.append(data[3])\n",
    "file.close()\n",
    "print(title[:2])\n",
    "# print(body[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add sentence start and end, then pad??\n",
    "\n",
    "# tokenize\n",
    "from nltk import word_tokenize\n",
    "t = title[1]\n",
    "b = body[1]\n",
    "# print(word_tokenize(b))\n",
    "tokens = nltk.wordpunct_tokenize(b)\n",
    "# tokens = tokens[20:] #select tokens\n",
    "text = nltk.Text(tokens)\n",
    "words = [w.lower() for w in text] # lower, DG, UNK...\n",
    "vocab = sorted(set(words))[1:100000]\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\", 'sweet', 'and', 'sour', 'sit', 'down', 'to', 'dessert', \"'\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "[porter.stem(t) for t in tokens]\n",
    "# [lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'RHUBARB is an alarmingly sour vegetable passed off as a fruit, but \"\n",
      " 'requiring a huge mound of sugar to effect the transformation.Crumb cake is a '\n",
      " 'huge mound of sugar disguised as a cake, but demanding a bracing '\n",
      " 'counterpoint -- say a swallow of coffee or tea -- to allay its cloying '\n",
      " 'sweetness.These two truths coexisted in my mind without overlapping until I '\n",
      " 'bit into a piece of crumb cake so texturally perfect (soft sliver of cake '\n",
      " 'topped by a deep layer of grape-size crumbs), yet so toothachingly sweet '\n",
      " 'that the only antidote was sucking on the lemon in my seltzer.The sourness '\n",
      " 'of the lemon immediately made me think about the rhubarb I had in the '\n",
      " 'fridge.',\n",
      " 'It occurred to me that, instead of cutting its tartness with a mountain of '\n",
      " \"sugar, why not mix the rhubarb into a crumb cake to cut the cake's \"\n",
      " \"sweetness?It was an ''Aha!''\",\n",
      " 'moment, as when some forebear first paired caviar with Champagne.']\n"
     ]
    }
   ],
   "source": [
    "# sentence segmentation 1\n",
    "sents = nltk.sent_tokenize(b)\n",
    "pprint.pprint(sents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"'\",\n",
       "  'RHUBARB',\n",
       "  'is',\n",
       "  'an',\n",
       "  'alarmingly',\n",
       "  'sour',\n",
       "  'vegetable',\n",
       "  'passed',\n",
       "  'off',\n",
       "  'as',\n",
       "  'a',\n",
       "  'fruit',\n",
       "  ',',\n",
       "  'but',\n",
       "  'requiring',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'mound',\n",
       "  'of',\n",
       "  'sugar',\n",
       "  'to',\n",
       "  'effect',\n",
       "  'the',\n",
       "  'transformation',\n",
       "  '.'],\n",
       " ['Crumb',\n",
       "  'cake',\n",
       "  'is',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'mound',\n",
       "  'of',\n",
       "  'sugar',\n",
       "  'disguised',\n",
       "  'as',\n",
       "  'a',\n",
       "  'cake',\n",
       "  ',',\n",
       "  'but',\n",
       "  'demanding',\n",
       "  'a',\n",
       "  'bracing',\n",
       "  'counterpoint',\n",
       "  '--',\n",
       "  'say',\n",
       "  'a',\n",
       "  'swallow',\n",
       "  'of',\n",
       "  'coffee',\n",
       "  'or',\n",
       "  'tea',\n",
       "  '--',\n",
       "  'to',\n",
       "  'allay',\n",
       "  'its',\n",
       "  'cloying',\n",
       "  'sweetness',\n",
       "  '.']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence segmentation 2, use option 2\n",
    "import sent_segment\n",
    "sent_segment.segment_sentences(tokens)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "# from w266_common import utils, vocabulary, tf_embed_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=None):\n",
    "    assert(learning_rate is not None)\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        feed_dict = {\n",
    "            lm.input_w_: w,\n",
    "            lm.target_y_: y,\n",
    "            lm.initial_h_: h,\n",
    "            lm.learning_rate_: learning_rate,\n",
    "            lm.use_dropout_: use_dropout\n",
    "        }\n",
    "        ops = [loss, lm.final_h_, train_op]        \n",
    "        #### YOUR CODE HERE ####\n",
    "        # session.run(...) the ops with the feed_dict constructed above.\n",
    "        # Ensure \"cost\" becomes the value of \"loss\".\n",
    "        # Hint: see \"ops\" for other variables that need updating in this loop.\n",
    "        cost = 0.0\n",
    "        vals = session.run(ops, feed_dict)\n",
    "        cost = vals[0] #loss\n",
    "        h = vals[1] #final_h\n",
    "\n",
    "\n",
    "          \n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "                i, total_words, avg_wps, avg_cost))\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.rnnlm_batch_generator(ids, batch_size=100, max_time=100)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=0.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print(\"{:s}: avg. loss: {:.03f}  (perplexity: {:.02f})\".format(name, cost, np.exp(cost)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "V = 10000\n",
    "vocab, train_ids, test_ids = utils.load_corpus(\"brown\", split=0.8, V=V, shuffle=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 25\n",
    "batch_size = 100\n",
    "learning_rate = 0.05 #default 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=200, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=2)\n",
    "\n",
    "TF_SAVEDIR = \"/tmp/w266/a3_model\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = utils.rnnlm_batch_generator(train_ids, batch_size, max_time)\n",
    "        print(\"[epoch {:d}] Starting epoch {:d}\".format(epoch, epoch))\n",
    "        #### YOUR CODE HERE ####\n",
    "        # Run a training epoch.    \n",
    "        cost = run_epoch(lm, session, bi, \n",
    "                 learning_rate=learning_rate, train=True, \n",
    "                 verbose=True, tick_s=10)\n",
    "        print(\"loss: {:.03f}  (perplexity: {:.02f})\".format(cost, np.exp(cost)))\n",
    "\n",
    "        #### END(YOUR CODE) ####\n",
    "        print(\"[epoch {:d}] Completed in {:s}\".format(epoch, utils.pretty_timedelta(since=t0_epoch)))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "#         if epoch == num_epochs:\n",
    "        print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "        print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seq(lm, session, seq, vocab):\n",
    "    \"\"\"Score a sequence of words. Returns total log-probability.\"\"\"\n",
    "    padded_ids = vocab.words_to_ids(utils.canonicalize_words([\"<s>\"] + seq + [\"</s>\"], \n",
    "                                                             wordset=vocab.word_to_id))\n",
    "    w = np.reshape(padded_ids[:-1], [1,-1])\n",
    "    y = np.reshape(padded_ids[1:],  [1,-1])\n",
    "    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "    feed_dict = {lm.input_w_:w,\n",
    "                 lm.target_y_:y,\n",
    "                 lm.initial_h_:h,\n",
    "                 lm.dropout_keep_prob_: 1.0}\n",
    "    # Return log(P(seq)) = -1*loss\n",
    "    return -1*session.run(lm.loss_, feed_dict)\n",
    "\n",
    "def load_and_score(inputs, sort=False):\n",
    "    \"\"\"Load the trained model and score the given words.\"\"\"\n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph=lm.graph) as session:  \n",
    "        # Load the trained model\n",
    "        saver.restore(session, trained_filename)\n",
    "\n",
    "        if isinstance(inputs[0], str) or isinstance(inputs[0], bytes):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # Actually run scoring\n",
    "        results = []\n",
    "        for words in inputs:\n",
    "            score = score_seq(lm, session, words, vocab)\n",
    "            results.append((score, words))\n",
    "\n",
    "        # Sort if requested\n",
    "        if sort: results = sorted(results, reverse=True)\n",
    "\n",
    "        # Print results\n",
    "        for score, words in results:\n",
    "            print(\"\\\"{:s}\\\" : {:.02f}\".format(\" \".join(words), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents = [\"once upon a time\",\n",
    "         \"the quick brown fox jumps over the lazy dog\"]\n",
    "load_and_score([s.split() for s in sents])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
